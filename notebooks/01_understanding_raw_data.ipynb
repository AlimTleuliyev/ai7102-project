{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078e61d1",
   "metadata": {},
   "source": [
    "# Part 1: Understanding the Pipeline - Input ‚Üí Output\n",
    "\n",
    "## üéØ What Actually Happens?\n",
    "\n",
    "Let's follow the REAL pipeline step by step:\n",
    "\n",
    "```\n",
    "Step 1: INPUT  ‚Üí JSON file (text with context/target pairs)\n",
    "Step 2: MODEL  ‚Üí Reads JSON, calculates surprisal \n",
    "Step 3: OUTPUT ‚Üí scores.json (surprisal per word)\n",
    "Step 4: MERGE  ‚Üí Combine with eye-tracking CSV\n",
    "Step 5: STATS  ‚Üí Regression analysis ‚Üí PPP score\n",
    "```\n",
    "\n",
    "## Let's see each piece of REAL data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fc674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d8071",
   "metadata": {},
   "source": [
    "## STEP 1: MODEL INPUT - What does calc_surprisal_hf.py receive?\n",
    "\n",
    "**File**: `data/DC/ngram_2-contextfunc_delete.json`\n",
    "\n",
    "This is the ACTUAL input to the model. Let's see what's inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eeda357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîµ MODEL INPUT (what calc_surprisal_hf.py reads)\n",
      "======================================================================\n",
      "Type: <class 'dict'>\n",
      "Number of articles: 20\n",
      "Article IDs: ['1', '2', '3', '4', '5']...\n",
      "\n",
      "Structure: dict[article_id] = list of (context, target) tuples\n",
      "======================================================================\n",
      "\n",
      " Article '1' contains 2573 word pieces\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the ACTUAL model input\n",
    "json_path = '../data/DC/ngram_2-contextfunc_delete.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    model_input = json.load(f)\n",
    "\n",
    "print(\"üîµ MODEL INPUT (what calc_surprisal_hf.py reads)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Type: {type(model_input)}\")\n",
    "print(f\"Number of articles: {len(model_input)}\")\n",
    "print(f\"Article IDs: {list(model_input.keys())[:5]}...\")\n",
    "print(f\"\\nStructure: dict[article_id] = list of (context, target) tuples\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "article_1 = model_input['1']\n",
    "print(f\"\\n Article '1' contains {len(article_1)} word pieces\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6eee565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 (context, target) pairs that the model will process:\n",
      "----------------------------------------------------------------------\n",
      "1. Context: '<EMPTY>'\n",
      "   Target:  'Are'\n",
      "\n",
      "2. Context: 'Are'\n",
      "   Target:  'tourists'\n",
      "\n",
      "3. Context: 'tourists'\n",
      "   Target:  'ent iced'\n",
      "\n",
      "4. Context: 'ent iced'\n",
      "   Target:  'by'\n",
      "\n",
      "5. Context: 'by'\n",
      "   Target:  'these'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 actual (context, target) pairs\n",
    "print(\"First 5 (context, target) pairs that the model will process:\")\n",
    "print(\"-\"*70)\n",
    "for i, (context, target) in enumerate(article_1[:5]):\n",
    "    context_display = context.replace('‚ñÅ', ' ').strip() if context.strip() else '<EMPTY>'\n",
    "    target_display = target.replace('‚ñÅ', ' ').strip()\n",
    "    print(f\"{i+1}. Context: '{context_display}'\")\n",
    "    print(f\"   Target:  '{target_display}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bed2af",
   "metadata": {},
   "source": [
    "## What does this mean?\n",
    "\n",
    "**Context**: What the model can see (previous words)  \n",
    "**Target**: What the model must predict (next word)\n",
    "\n",
    "For 2-gram: context = only the LAST 1 word (that's why many contexts are short!)\n",
    "\n",
    "The model's job: Given context, calculate probability of target ‚Üí Convert to surprisal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d571a517",
   "metadata": {},
   "source": [
    "## STEP 2: MODEL OUTPUT - What does calc_surprisal_hf.py produce?\n",
    "\n",
    "**File**: `surprisals/quick-test/arch_gpt2-ngram_2-contextfunc_delete/scores.json`\n",
    "\n",
    "After running the model, we get surprisal scores. Let's look at the ACTUAL output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538b1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT (what calc_surprisal_hf.py produces)\n",
      "======================================================================\n",
      "Type: <class 'dict'>\n",
      "Number of articles: 20\n",
      "Article IDs: ['1', '2', '3', '4', '5']...\n",
      "\n",
      "Structure: dict[article_id] = list of surprisal values (floats)\n",
      "======================================================================\n",
      "\n",
      " Article '1' has 2573 surprisal scores\n",
      "\n",
      "First 10 surprisal scores:\n",
      "----------------------------------------------------------------------\n",
      "Word 1: surprisal = 12.3294\n",
      "Word 2: surprisal = 11.6519\n",
      "Word 3: surprisal = 11.4062\n",
      "Word 4: surprisal = 1.1518\n",
      "Word 5: surprisal = 6.3439\n",
      "Word 6: surprisal = 10.7538\n",
      "Word 7: surprisal = 11.1548\n",
      "Word 8: surprisal = 5.6977\n",
      "Word 9: surprisal = 6.3907\n",
      "Word 10: surprisal = 14.4223\n",
      "\n",
      " Higher surprisal = model was more 'surprised' (word was unexpected)\n"
     ]
    }
   ],
   "source": [
    "# Load the ACTUAL model output from our quick test\n",
    "scores_path = '../surprisals/quick-test/arch_gpt2-ngram_2-contextfunc_delete/scores.json'\n",
    "with open(scores_path, 'r') as f:\n",
    "    model_output = json.load(f)\n",
    "\n",
    "print(\"MODEL OUTPUT (what calc_surprisal_hf.py produces)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Type: {type(model_output)}\")\n",
    "print(f\"Number of articles: {len(model_output)}\")\n",
    "print(f\"Article IDs: {list(model_output.keys())[:5]}...\")\n",
    "print(f\"\\nStructure: dict[article_id] = list of surprisal values (floats)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Look at Article 1 output\n",
    "article_1_scores = model_output['1']\n",
    "print(f\"\\n Article '1' has {len(article_1_scores)} surprisal scores\\n\")\n",
    "\n",
    "# Show first 10 surprisal values\n",
    "print(\"First 10 surprisal scores:\")\n",
    "print(\"-\"*70)\n",
    "for i, score in enumerate(article_1_scores[:10]):\n",
    "    print(f\"Word {i+1}: surprisal = {score:.4f}\")\n",
    "\n",
    "print(f\"\\n Higher surprisal = model was more 'surprised' (word was unexpected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfe00a",
   "metadata": {},
   "source": [
    "## STEP 3: HUMAN DATA - What do we compare against?\n",
    "\n",
    "**File**: `data/DC/all.txt.annotation.filtered.csv`\n",
    "\n",
    "This contains REAL human reading times. Let's see the ACTUAL structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de98251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ HUMAN DATA (what dundee.py uses for regression)\n",
      "======================================================================\n",
      "Shape: (515010, 106) (rows √ó columns)\n",
      "Total observations: 515,010\n",
      "\n",
      "Key columns:\n",
      "  - article: which article (1-20)\n",
      "  - subj_id: which person read it\n",
      "  - time: gaze duration in milliseconds (THE TARGET VARIABLE)\n",
      "  - length: word length\n",
      "  - log_gmean_freq: word frequency\n",
      "======================================================================\n",
      "\n",
      "First 10 rows (article 1, subject sf):\n",
      " article subj_id  wnum  time  length  log_gmean_freq  pos\n",
      "       1      sf     1     0       3        7.684325  VBP\n",
      "       1      sf     2   294       8        7.246369  NNS\n",
      "       1      sf     3   364       7        7.834414  VBN\n",
      "       1      sf     4     0       2       13.302279   IN\n",
      "       1      sf     5   234       5       10.752163   DT\n",
      "       1      sf     6   322      11        6.527959  NNS\n",
      "       1      sf     7   307      11        7.180071  VBG\n",
      "       1      sf     8   256       5       12.134303 PRP$\n",
      "       1      sf     9     0       4       10.273982   JJ\n",
      "       1      sf    10   312      10        8.638401   NN\n"
     ]
    }
   ],
   "source": [
    "# Load the ACTUAL human reading data\n",
    "csv_path = '../data/DC/all.txt.annotation.filtered.csv'\n",
    "human_data = pd.read_csv(csv_path, sep='\\t')\n",
    "\n",
    "print(\"üü¢ HUMAN DATA (what dundee.py uses for regression)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape: {human_data.shape} (rows √ó columns)\")\n",
    "print(f\"Total observations: {len(human_data):,}\")\n",
    "print(f\"\\nKey columns:\")\n",
    "print(f\"  - article: which article (1-20)\")\n",
    "print(f\"  - subj_id: which person read it\")  \n",
    "print(f\"  - time: gaze duration in milliseconds (THE TARGET VARIABLE)\")\n",
    "print(f\"  - length: word length\")\n",
    "print(f\"  - log_gmean_freq: word frequency\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Show first 10 rows - ONLY relevant columns\n",
    "key_cols = ['article', 'subj_id', 'wnum', 'time', 'length', 'log_gmean_freq', 'pos']\n",
    "print(f\"\\nFirst 10 rows (article 1, subject {human_data['subj_id'].iloc[0]}):\")\n",
    "print(human_data[human_data['article']==1].head(10)[key_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f2b5c",
   "metadata": {},
   "source": [
    "## STEP 4: MERGE - How do convert_scores.py combine them?\n",
    "\n",
    "**Script**: `convert_scores.py`\n",
    "\n",
    "It takes scores.json and adds 3 columns to create scores.csv:\n",
    "- `surprisals_sum` (current word surprisal)\n",
    "- `surprisals_sum_prev_1` (previous word surprisal)\n",
    "- `surprisals_sum_prev_2` (2 words ago surprisal)\n",
    "\n",
    "Let's see the ACTUAL merged output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535158a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MERGED DATA (convert_scores.py output)\n",
      "======================================================================\n",
      "Shape: (515010, 4)\n",
      "Columns: ['surprisals_sum', 'surprisals_sum_prev_1', 'surprisals_sum_prev_2', 'surprisals_sum_prev_3']\n",
      "======================================================================\n",
      "\n",
      "First 10 rows:\n",
      " surprisals_sum  surprisals_sum_prev_1  surprisals_sum_prev_2  surprisals_sum_prev_3\n",
      "      12.329370               7.502281               7.502281               7.502281\n",
      "      11.651941              12.329370               7.502281               7.502281\n",
      "      11.406207              11.651941              12.329370               7.502281\n",
      "       1.151818              11.406207              11.651941              12.329370\n",
      "       6.343907               1.151818              11.406207              11.651941\n",
      "      10.753804               6.343907               1.151818              11.406207\n",
      "      11.154766              10.753804               6.343907               1.151818\n",
      "       5.697666              11.154766              10.753804               6.343907\n",
      "       6.390707               5.697666              11.154766              10.753804\n",
      "      14.422316               6.390707               5.697666              11.154766\n",
      "\n",
      "üí° These surprisal columns will be added to the human data CSV\n"
     ]
    }
   ],
   "source": [
    "# Load the ACTUAL merged output\n",
    "scores_csv_path = '../surprisals/quick-test/arch_gpt2-ngram_2-contextfunc_delete/scores.csv'\n",
    "merged_scores = pd.read_csv(scores_csv_path, sep='\\t')\n",
    "\n",
    "print(\" MERGED DATA (convert_scores.py output)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape: {merged_scores.shape}\")\n",
    "print(f\"Columns: {list(merged_scores.columns)}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(merged_scores.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° These surprisal columns will be added to the human data CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45842a8",
   "metadata": {},
   "source": [
    "## STEP 5: REGRESSION - What does dundee.py do?\n",
    "\n",
    "**Script**: `dundee.py`\n",
    "\n",
    "It combines the human CSV with surprisal scores and runs 2 regression models:\n",
    "\n",
    "**Baseline**: `time ~ length * freq + controls + random_effects`  \n",
    "**Test**: `time ~ length * freq + **surprisals_sum** + controls + random_effects`\n",
    "\n",
    "Then compares: Does adding surprisal improve prediction?\n",
    "\n",
    "Let's see the ACTUAL output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca0c38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL OUTPUT (dundee.py result)\n",
      "======================================================================\n",
      "linear_fit_logLik: -5.94250763908901\n",
      "delta_linear_fit_logLik: 0.007719792489860211\n",
      "delta_linear_fit_chi_p: 0.0\n",
      "\n",
      "# Additional metrics:\n",
      "base_loglik_total: -1265309.9130978151\n",
      "test_loglik_total: -1263668.306944639\n",
      "lr_statistic: 3283.2123063523322\n",
      "n_observations: 212649\n",
      "\n",
      "======================================================================\n",
      "\n",
      "‚úÖ PPP (Psychometric Predictive Power) = 0.007720\n",
      "   This means: Adding surprisal improved the model!\n",
      "   Higher PPP = surprisal predicts human reading time better\n"
     ]
    }
   ],
   "source": [
    "# Load the ACTUAL regression output\n",
    "likelihood_path = '../surprisals/quick-test/arch_gpt2-ngram_2-contextfunc_delete/likelihood.txt'\n",
    "with open(likelihood_path, 'r') as f:\n",
    "    output_text = f.read()\n",
    "\n",
    "print(\"FINAL OUTPUT (dundee.py result)\")\n",
    "print(\"=\"*70)\n",
    "print(output_text)\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Parse the values\n",
    "lines = output_text.strip().split('\\n')\n",
    "for line in lines:\n",
    "    if 'delta_linear_fit_logLik' in line:\n",
    "        ppp = float(line.split(':')[1].strip())\n",
    "        print(f\"\\n‚úÖ PPP (Psychometric Predictive Power) = {ppp:.6f}\")\n",
    "        print(f\"   This means: Adding surprisal improved the model!\")\n",
    "        print(f\"   Higher PPP = surprisal predicts human reading time better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2bd5db",
   "metadata": {},
   "source": [
    "## \udcca COMPLETE PIPELINE SUMMARY\n",
    "\n",
    "```\n",
    "INPUT:  ngram_2-contextfunc_delete.json\n",
    "        ‚Üì (context, target) pairs\n",
    "        \n",
    "STEP 1: calc_surprisal_hf.py -m gpt2 -d INPUT -o OUTPUT\n",
    "        Model reads JSON, calculates surprisal\n",
    "        ‚Üì\n",
    "        \n",
    "OUTPUT: scores.json  \n",
    "        {article_id: [surprisal1, surprisal2, ...]}\n",
    "        ‚Üì\n",
    "        \n",
    "STEP 2: convert_scores.py --dir OUTPUT\n",
    "        Add lag features (prev_1, prev_2)\n",
    "        ‚Üì\n",
    "        \n",
    "OUTPUT: scores.csv\n",
    "        [surprisals_sum, surprisals_sum_prev_1, surprisals_sum_prev_2]\n",
    "        ‚Üì\n",
    "        \n",
    "STEP 3: dundee.py OUTPUT/\n",
    "        Merge with human CSV (all.txt.annotation.filtered.csv)\n",
    "        Run regression: time ~ surprisal + length + freq + ...\n",
    "        ‚Üì\n",
    "        \n",
    "OUTPUT: likelihood.txt\n",
    "        PPP = delta_logLik (how much surprisal helps predict reading time)\n",
    "```\n",
    "\n",
    "### Real Files in Our Test:\n",
    "‚úÖ Input: `data/DC/ngram_2-contextfunc_delete.json` (2573 word pieces)  \n",
    "‚úÖ Output 1: `surprisals/.../scores.json` (2573 surprisal values)  \n",
    "‚úÖ Output 2: `surprisals/.../scores.csv` (2573 rows √ó 4 columns)  \n",
    "‚úÖ Human data: `data/DC/all.txt.annotation.filtered.csv` (515,010 observations)  \n",
    "‚úÖ Final: `surprisals/.../likelihood.txt` (PPP = 0.0077)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331e47d",
   "metadata": {},
   "source": [
    "## ‚úÖ Now Do You Understand?\n",
    "\n",
    "### The Pipeline in Simple Terms:\n",
    "\n",
    "**INPUT**: Text with limited context (JSON)  \n",
    "**MODEL**: GPT-2 calculates \"how surprised am I by each word?\"  \n",
    "**OUTPUT**: Surprisal scores (JSON ‚Üí CSV)  \n",
    "**MERGE**: Combine surprisal with human reading times  \n",
    "**ANALYSIS**: Does surprisal predict reading time? ‚Üí **YES! PPP = 0.0077**\n",
    "\n",
    "### Key Files You Just Saw:\n",
    "1. `ngram_2-contextfunc_delete.json` - What model sees (input)\n",
    "2. `scores.json` - Model's surprisal values (output)\n",
    "3. `scores.csv` - Surprisal with lag features\n",
    "4. `all.txt.annotation.filtered.csv` - Human reading times\n",
    "5. `likelihood.txt` - Final PPP score\n",
    "\n",
    "### Questions?\n",
    "1. What goes INTO calc_surprisal_hf.py? ‚Üí **JSON with (context, target) pairs**\n",
    "2. What comes OUT of calc_surprisal_hf.py? ‚Üí **scores.json with surprisal values**\n",
    "3. What does dundee.py do? ‚Üí **Regression: time ~ surprisal + other_features**\n",
    "4. What is PPP? ‚Üí **How much surprisal improves reading time prediction**\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for Part 2?** Now we'll understand WHY we have 31 different JSON files (different context lengths)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
